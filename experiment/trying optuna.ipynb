{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99320b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174e67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0e5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "file_path = '../data/Loan_Data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4925b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning a bit\n",
    "\n",
    "# 1. drop id col\n",
    "df.drop(columns = ['Loan_ID'], inplace=True)\n",
    "\n",
    "# 2. drop dupe\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 2.1 drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# 3. classify num and cat columns\n",
    "\n",
    "cat_columns = [column for column in df.columns if df[column].dtype == 'object']\n",
    "num_columns = [column for column in df.columns if df[column].dtype != 'object']\n",
    "\n",
    "cat_columns.remove('Loan_Status')\n",
    "\n",
    "\n",
    "\n",
    "# 4. split to training and testing set\n",
    "\n",
    "X = df.drop(columns = 'Loan_Status').copy()\n",
    "y = df['Loan_Status'].copy()\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                    random_state=42,  \n",
    "                                    test_size=0.1,\n",
    "                                    shuffle=True)\n",
    "\n",
    "\n",
    "# 5. encoder\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encoder.fit(X_train[cat_columns])\n",
    "\n",
    "X_train[cat_columns] = encoder.transform(X_train[cat_columns])    \n",
    "X_test[cat_columns] = encoder.transform(X_test[cat_columns])\n",
    "\n",
    "\n",
    "# 6. scale\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4fdcc4a",
   "metadata": {},
   "source": [
    "# Optuna Part + MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c474405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_logging(exp_param, model, params:dict, metrics:dict):\n",
    "\n",
    "    experiment_name = exp_param['name']\n",
    "    run_name = exp_param['run_name']\n",
    "    artifact_path = exp_param['artifact_path']\n",
    "    model_name = exp_param['model_name']\n",
    "    signature = exp_param['signature']\n",
    "\n",
    "\n",
    "    # set experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "\n",
    "    # initiate the logging\n",
    "    with mlflow.start_run(run_name = run_name, nested=True) as run:\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "\n",
    "        # Log an instance of the trained model for later use\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,  \n",
    "            artifact_path=artifact_path,\n",
    "            registered_model_name= model_name,\n",
    "            signature=signature\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8298798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up mlflow client\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f536614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiment\n",
    "\n",
    "experiment_description = (\n",
    "    \"This is the application loan prediction project\"\n",
    "    \"This experiment contains the base experiments made\"\n",
    ")\n",
    "\n",
    "data_clean_made = (\n",
    "    \"remove id col, remove duplicate, [remove missing], categorical encoder, standard scaler\"\n",
    ")\n",
    "\n",
    "model_involved = (\n",
    "    \"Logistic Regression\"\n",
    "    \"AdaBoost\"\n",
    ")\n",
    "\n",
    "other_tag = (\n",
    "    \"Optuna\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"loan_application_project\",\n",
    "    \"team\": \"syamil\",\n",
    "    \"project_quarter\": \"Q1-2024\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "    \"data_cleaning\" : data_clean_made,\n",
    "    \"mode_involved\" : model_involved,\n",
    "    \"other_tag\" : other_tag\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "create_experiment = client.create_experiment(\n",
    "    name=\"Loan_Application_Classification\", tags=experiment_tags\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742c367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'first_experiment'\n",
    "run_name = \"first_run\"\n",
    "artifact_path = 'loan_application_model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58eb8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_ex, X_train, y_train, X_test, y_test, params:dict):\n",
    "\n",
    "    #logging.info(\"Running up Logistic Regression...\")\n",
    "\n",
    "    # run logistic regression model\n",
    "    model = model_ex.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_valid = model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "    # trying to get the signature \n",
    "    # -> (responsible to save the schema of model input and output)\n",
    "    predictions = model.predict(X_test)\n",
    "    signature = infer_signature(X_test, predictions)\n",
    "    \n",
    "    \n",
    "    return model, score_train, score_valid, signature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2336413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna code\n",
    "\n",
    "def objective(trial, name, model):\n",
    "    \n",
    "    #with mlflow.start_run(nested=True):\n",
    "    \n",
    "    \n",
    "        # Adaboost classification\n",
    "        if name == 'AdaBoost':\n",
    "            params = {\n",
    "                'n_estimators' : trial.suggest_int('n_estimators',100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate',0.0, 1.0),\n",
    "                'algorithm' : trial.suggest_categorical('algorithm',['SAMME','SAMME.R'])\n",
    "            }\n",
    "            \n",
    "        # Logistic Regression\n",
    "        elif name == 'Logistic_Regression':    \n",
    "\n",
    "            penalty_choices = ['l1', 'l2', 'elasticnet']\n",
    "\n",
    "            params = {\n",
    "                #'penalty' : trial.suggest_categorical('penalty', [None, 'l2', 'l1', 'elasticnet']),\n",
    "                'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "                'solver': trial.suggest_categorical('solver', ['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']),\n",
    "                'max_iter': trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "        model = model.set_params(**params)\n",
    "\n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "        score\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "#study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "\n",
    "#study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a44f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'base_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d80103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-04 14:39:42,166] A new study created in memory with name: no-name-b94a7433-bb39-45fb-a987-392475503109\n",
      "[I 2024-05-04 14:39:42,283] Trial 0 finished with value: 0.7543972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'sag', 'max_iter': 738}. Best is trial 0 with value: 0.7543972199946538.\n",
      "[I 2024-05-04 14:39:42,386] Trial 1 finished with value: 0.7543972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 243}. Best is trial 0 with value: 0.7543972199946538.\n",
      "[I 2024-05-04 14:39:42,462] Trial 2 finished with value: 0.7986367281475542 and parameters: {'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 977}. Best is trial 2 with value: 0.7986367281475542.\n",
      "[I 2024-05-04 14:39:42,555] Trial 3 finished with value: 0.7986367281475542 and parameters: {'class_weight': None, 'solver': 'saga', 'max_iter': 945}. Best is trial 2 with value: 0.7986367281475542.\n",
      "[I 2024-05-04 14:39:42,624] Trial 4 finished with value: 0.7986367281475542 and parameters: {'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 160}. Best is trial 2 with value: 0.7986367281475542.\n",
      "2024/05/04 14:39:43 INFO mlflow.tracking.fluent: Experiment with name 'Loan_Application_Classification' does not exist. Creating a new experiment.\n",
      "Registered model 'Logistic_Regression_best_params' already exists. Creating a new version of this model...\n",
      "Created version '10' of model 'Logistic_Regression_best_params'.\n"
     ]
    }
   ],
   "source": [
    "# trying to combine two classifier\n",
    "\n",
    "names = [\n",
    "    'Logistic_Regression',\n",
    "    #'AdaBoost'\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    #AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "optuna_study = {}\n",
    "\n",
    "def model_training(model, X_train, y_train, X_test, y_test):\n",
    "    model_fitted = model.fit(X_train, y_train)\n",
    "    y_pred = model_fitted.predict(X_test)\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    return model, round(score,3)\n",
    "\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    \n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name) as parent_run:\n",
    "        \n",
    "        # get mlflow id\n",
    "        run_id = parent_run.info.run_id\n",
    "        \n",
    "        #score = model_training(model,X_train, y_train, X_test, y_test)\n",
    "        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "        objective_fn = lambda trial: objective(trial, name, model)\n",
    "        study.optimize(objective_fn, n_trials=5)\n",
    "        \n",
    "        for i, trial in enumerate(study.trials):\n",
    "            with mlflow.start_run(run_name=f\"{run_name}_{name}_trial_{i+1}\",nested=True):\n",
    "                mlflow.log_params(trial.params)\n",
    "                mlflow.log_metric('accuracy', trial.value)    \n",
    "            \n",
    "                \n",
    "        \n",
    "        # update the best model run with unseen data\n",
    "        \n",
    "        model, score_train, score_valid, signature = train_model(model, X_train, y_train, X_test, y_test, study.best_params)\n",
    "\n",
    "        # update the run in experiemnt\n",
    "        exp_param = {\n",
    "            'name' : 'Loan_Application_Classification',\n",
    "            'run_name': f'{run_name}_{name}_best_params',\n",
    "            'artifact_path': f'loan_application_model/{run_name}',\n",
    "            'model_name': f'{name}_best_params', \n",
    "            'signature': signature\n",
    "        }\n",
    "        \n",
    "        model_params = study.best_params\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy Training' : score_train,\n",
    "            'Accuracy Test' : score_valid \n",
    "        }\n",
    "        \n",
    "        mlflow_logging(exp_param, model, model_params, metrics)\n",
    "\n",
    "        optuna_study[name] = study\n",
    "\n",
    "        #print(f'{name}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dbf5c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Study.trials_dataframe of <optuna.study.study.Study object at 0x0000025E97BC3A60>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study['Logistic_Regression'].trials_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c35ddc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ask',\n",
       " '_directions',\n",
       " '_get_trials',\n",
       " '_is_multi_objective',\n",
       " '_log_completed_trial',\n",
       " '_pop_waiting_trial_id',\n",
       " '_should_skip_enqueue',\n",
       " '_stop_flag',\n",
       " '_storage',\n",
       " '_study_id',\n",
       " '_tell',\n",
       " '_thread_local',\n",
       " 'add_trial',\n",
       " 'add_trials',\n",
       " 'ask',\n",
       " 'best_params',\n",
       " 'best_trial',\n",
       " 'best_trials',\n",
       " 'best_value',\n",
       " 'direction',\n",
       " 'directions',\n",
       " 'enqueue_trial',\n",
       " 'get_trials',\n",
       " 'metric_names',\n",
       " 'optimize',\n",
       " 'pruner',\n",
       " 'sampler',\n",
       " 'set_metric_names',\n",
       " 'set_system_attr',\n",
       " 'set_user_attr',\n",
       " 'stop',\n",
       " 'study_name',\n",
       " 'system_attrs',\n",
       " 'tell',\n",
       " 'trials',\n",
       " 'trials_dataframe',\n",
       " 'user_attrs']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optuna_study['Logistic_Regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57340e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a7fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d461d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/405433576641488242', creation_time=1714804783920, experiment_id='405433576641488242', last_update_time=1714804783920, lifecycle_stage='active', name='Loan_Application_Classification', tags={}>,\n",
       " <Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/279795776414714051', creation_time=1714740930270, experiment_id='279795776414714051', last_update_time=1714740930270, lifecycle_stage='active', name='EX_2_Loan_Application_Classification_v4', tags={}>,\n",
       " <Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/566338987520218507', creation_time=1714276198462, experiment_id='566338987520218507', last_update_time=1714276198462, lifecycle_stage='active', name='EX_2_Loan_Application_Classification_2', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/938531224314861096', creation_time=1714273451264, experiment_id='938531224314861096', last_update_time=1714273451264, lifecycle_stage='active', name='testing_boi', tags={'priority': 'P1', 'version': 'v1'}>,\n",
       " <Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/0', creation_time=1713012293169, experiment_id='0', last_update_time=1713012293169, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get experiment info\n",
    "\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a45242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=AdaBoost_best_params; run_id=0a9ead84023342a1b3646b9456a3eef8; version=7, stage=None\n",
      "name=Logistic_Regression_best_params; run_id=ab1064e8fc734327ae5ca9cf66ba70e7; version=1, stage=Production\n",
      "name=Logistic_Regression_best_params; run_id=a6076f965e81432793a0d16f93fac0f1; version=10, stage=None\n"
     ]
    }
   ],
   "source": [
    "for model in client.search_registered_models(filter_string=\"name LIKE '%'\"):\n",
    "    for model_version in model.latest_versions:\n",
    "        if model_version.current_stage == 'Production':\n",
    "            deployment_model = model_version\n",
    "        print(f\"name={model_version.name}; run_id={model_version.run_id}; version={model_version.version}, stage={model_version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fb830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=['champion'], creation_timestamp=1713066172078, current_stage='Production', description=None, last_updated_timestamp=1713066612943, name='Logistic_Regression_best_params', run_id='ab1064e8fc734327ae5ca9cf66ba70e7', run_link=None, source='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/615822914642047264/ab1064e8fc734327ae5ca9cf66ba70e7/artifacts/loan_application_model/base_experiment', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e69b726",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'C:\\Users\\USER\\Desktop\\MLOPS NEW\\E2E Loan Application Classification\\E2E_Loan_Application\\experiment\\mlruns\\615822914642047264\\ab1064e8fc734327ae5ca9cf66ba70e7\\artifacts\\loan_application_model\\base_experiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_model\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/loan_application_model/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\mlflow\\pyfunc\\__init__.py:634\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[0;32m    601\u001b[0m     model_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    602\u001b[0m     suppress_warnings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    603\u001b[0m     dst_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    604\u001b[0m     model_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyFuncModel:\n\u001b[0;32m    606\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    Load a model stored in Python function format.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m                                             release without warning.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[0;32m    637\u001b[0m         model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:125\u001b[0m, in \u001b[0;36mRunsArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, artifact_path, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Download an artifact file or directory to a local directory if applicable, and return a\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    local path for it.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    :return: Absolute path of the local filesystem location containing the desired artifacts.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py:81\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m local_artifact_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(artifact_path))\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
      "\u001b[1;31mOSError\u001b[0m: No such file or directory: 'C:\\Users\\USER\\Desktop\\MLOPS NEW\\E2E Loan Application Classification\\E2E_Loan_Application\\experiment\\mlruns\\615822914642047264\\ab1064e8fc734327ae5ca9cf66ba70e7\\artifacts\\loan_application_model\\base_experiment'"
     ]
    }
   ],
   "source": [
    "model_path = f'runs:/{deployment_model.run_id}/loan_application_model/{run_name}'\n",
    "\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbfd1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/a6076f965e81432793a0d16f93fac0f1/loan_application_model/base_experiment'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f9b42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(loaded_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb431c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflowtest",
   "language": "python",
   "name": "mlflowtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
