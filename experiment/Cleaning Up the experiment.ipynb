{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3fae298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import mlflow\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# import hyper-parameter tuning tool\n",
    "import optuna\n",
    "\n",
    "# import compile steps\n",
    "from dsteps import data_ingestion as di\n",
    "from dsteps import data_transformation as dt\n",
    "from dsteps import model_training as mt\n",
    "import mlflow_exp as mle\n",
    "\n",
    "\n",
    "# model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# model validation include cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "# os\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cd761",
   "metadata": {},
   "source": [
    "# Define Dataset Path, Mlflow Client Server and So on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0fdfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path, mlflow client server and so on\n",
    "file_path = '../data/Loan_Data.csv'\n",
    "\n",
    "# set up mlflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment_name = \"EX_2_Loan_Application_Classification\"\n",
    "\n",
    "run_name = 'titi-base_experiment'\n",
    "\n",
    "n_trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc88251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b72b60",
   "metadata": {},
   "source": [
    "# Define MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938ee1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment EX_2_Loan_Application_Classification already_exist\n"
     ]
    }
   ],
   "source": [
    "# create experiment\n",
    "\n",
    "experiment_description = (\n",
    "    \"This is the second experiment of loan prediction project\"\n",
    "    \"This experiment contains the base experiments made\"\n",
    ")\n",
    "\n",
    "\n",
    "model_involved = (\n",
    "    \"Logistic Regression\"\n",
    "    \"AdaBoost\"\n",
    ")\n",
    "\n",
    "other_tag = (\n",
    "    \"Optuna\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"loan_application_project\",\n",
    "    \"team\": \"syamil\",\n",
    "    \"project_quarter\": \"Q1-2024\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "    \"mode_involved\" : model_involved,\n",
    "    \"other_tag\" : other_tag\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "try:\n",
    "    create_experiment = client.create_experiment(\n",
    "        name=experiment_name, tags=experiment_tags\n",
    "    )\n",
    "    print(f'Experiment {experiment_name} created')\n",
    "\n",
    "except:\n",
    "    print(f'Experiment {experiment_name} already_exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b05dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae1a5c0",
   "metadata": {},
   "source": [
    "# Start Your Experiment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3962dc",
   "metadata": {},
   "source": [
    "#### Maybe Data Preprocessing / Anything Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495c08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and transform\n",
    "\n",
    "df = di.data_ingest(file_path)\n",
    "X_train, y_train, X_test, y_test = dt.cleaning_train_pipeline(df)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa38717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "1   Male     Yes          1      Graduate            No             4583   \n",
       "2   Male     Yes          0      Graduate           Yes             3000   \n",
       "3   Male     Yes          0  Not Graduate            No             2583   \n",
       "4   Male      No          0      Graduate            No             6000   \n",
       "5   Male     Yes          2      Graduate           Yes             5417   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1             1508.0       128.0             360.0             1.0   \n",
       "2                0.0        66.0             360.0             1.0   \n",
       "3             2358.0       120.0             360.0             1.0   \n",
       "4                0.0       141.0             360.0             1.0   \n",
       "5             4196.0       267.0             360.0             1.0   \n",
       "\n",
       "  Property_Area Loan_Status  \n",
       "1         Rural           N  \n",
       "2         Urban           Y  \n",
       "3         Urban           Y  \n",
       "4         Urban           Y  \n",
       "5         Urban           Y  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507476d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c83b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09db7bfa",
   "metadata": {},
   "source": [
    "#### Model Experiment Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2521ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_study = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a8a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna code\n",
    "\n",
    "def objective(trial, name, model):\n",
    "    \n",
    "\n",
    "        # Adaboost classification\n",
    "        if name == 'AdaBoost':\n",
    "            params = {\n",
    "                'n_estimators' : trial.suggest_int('n_estimators',100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate',0.0, 1.0),\n",
    "                'algorithm' : trial.suggest_categorical('algorithm',['SAMME','SAMME.R'])\n",
    "            }\n",
    "            \n",
    "        # Logistic Regression\n",
    "        elif name == 'Logistic_Regression':    \n",
    "\n",
    "            penalty_choices = ['l1', 'l2', 'elasticnet']\n",
    "\n",
    "            params = {\n",
    "                #'penalty' : trial.suggest_categorical('penalty', [None, 'l2', 'l1', 'elasticnet']),\n",
    "                'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "                'solver': trial.suggest_categorical('solver', ['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']),\n",
    "                'max_iter': trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "        model = model.set_params(**params)\n",
    "\n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea43c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-14 20:36:47,171] A new study created in memory with name: no-name-390d171f-5daf-40fd-aa65-7b3446683983\n",
      "[I 2024-04-14 20:36:47,269] Trial 0 finished with value: 0.7986367281475542 and parameters: {'class_weight': None, 'solver': 'newton-cg', 'max_iter': 705}. Best is trial 0 with value: 0.7986367281475542.\n",
      "[I 2024-04-14 20:36:47,365] Trial 1 finished with value: 0.7543972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 300}. Best is trial 0 with value: 0.7986367281475542.\n",
      "[I 2024-04-14 20:36:47,448] Trial 2 finished with value: 0.7543972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 985}. Best is trial 0 with value: 0.7986367281475542.\n",
      "[I 2024-04-14 20:36:47,507] Trial 3 finished with value: 0.7986367281475542 and parameters: {'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 488}. Best is trial 0 with value: 0.7986367281475542.\n",
      "[I 2024-04-14 20:36:47,583] Trial 4 finished with value: 0.7543972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'saga', 'max_iter': 639}. Best is trial 0 with value: 0.7986367281475542.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'Logistic_Regression_best_params' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'Logistic_Regression_best_params'.\n",
      "[I 2024-04-14 20:36:56,319] A new study created in memory with name: no-name-6f80cad0-b148-4e2c-8d30-c5c8e0f9fcf1\n",
      "[I 2024-04-14 20:37:12,450] Trial 0 finished with value: 0.7916065223202352 and parameters: {'n_estimators': 612, 'learning_rate': 0.699249572053827, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.7916065223202352.\n",
      "[I 2024-04-14 20:37:29,760] Trial 1 finished with value: 0.7429296979417268 and parameters: {'n_estimators': 576, 'learning_rate': 0.574320480494052, 'algorithm': 'SAMME.R'}. Best is trial 0 with value: 0.7916065223202352.\n",
      "[I 2024-04-14 20:37:39,340] Trial 2 finished with value: 0.745308740978348 and parameters: {'n_estimators': 299, 'learning_rate': 0.7602161176360204, 'algorithm': 'SAMME.R'}. Best is trial 0 with value: 0.7916065223202352.\n",
      "[I 2024-04-14 20:37:47,204] Trial 3 finished with value: 0.789361133386795 and parameters: {'n_estimators': 289, 'learning_rate': 0.6695032423691398, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.7916065223202352.\n",
      "[I 2024-04-14 20:38:02,844] Trial 4 finished with value: 0.7591285752472601 and parameters: {'n_estimators': 516, 'learning_rate': 0.38590620758294303, 'algorithm': 'SAMME.R'}. Best is trial 0 with value: 0.7916065223202352.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'AdaBoost_best_params'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'AdaBoost_best_params'.\n"
     ]
    }
   ],
   "source": [
    "# trying to combine two classifier\n",
    "\n",
    "names = [\n",
    "    'Logistic_Regression',\n",
    "    'AdaBoost'\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    \n",
    "    \n",
    "    with mlflow.start_run(run_name=f'run_name_{name}') as parent_run:\n",
    "        \n",
    "        # get mlflow id\n",
    "        run_id = parent_run.info.run_id\n",
    "        \n",
    "        #score = model_training(model,X_train, y_train, X_test, y_test)\n",
    "        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "        objective_fn = lambda trial: objective(trial, name, model)\n",
    "        study.optimize(objective_fn, n_trials=n_trials)\n",
    "        \n",
    "        \n",
    "        ##  ---- Trial ------ ##\n",
    "        \n",
    "        # log the experiment result into mlflow\n",
    "        for i, trial in enumerate(study.trials):\n",
    "            with mlflow.start_run(run_name=f\"{run_name}_{name}_trial_{i+1}\",nested=True):\n",
    "                mlflow.log_params(trial.params)\n",
    "                mlflow.log_metric('accuracy', trial.value)    \n",
    "            \n",
    "                \n",
    "        ##  ---- Champion Model ------ ##\n",
    "        \n",
    "        # update the best model run with unseen data\n",
    "        model, score_train, score_valid, signature = mt.train_model(model, X_train, y_train, X_test, y_test, study.best_params)\n",
    "\n",
    "        # update the run in experiemnt\n",
    "        exp_run_param = {\n",
    "            'name' : f'{experiment_name}',\n",
    "            'run_name': f'{run_name}_{name}_best_params',\n",
    "            'artifact_path': f'loan_application_model/{run_name}',\n",
    "            'model_name': f'{name}_best_params', \n",
    "            'signature': signature\n",
    "        }\n",
    "        \n",
    "        model_params = study.best_params\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy Training' : score_train,\n",
    "            'Accuracy Test' : score_valid \n",
    "        }\n",
    "        \n",
    "        mle.mlflow_logging(exp_run_param, model, model_params, metrics)\n",
    "\n",
    "        optuna_study[name] = study\n",
    "\n",
    "        #print(f'{name}: {score}')\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4f948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maliciouness\n",
    "\n",
    "\n",
    "def model_training(model, X_train, y_train, X_test, y_test):\n",
    "    model_fitted = model.fit(X_train, y_train)\n",
    "    y_pred = model_fitted.predict(X_test)\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    return model, round(score,3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflowtest",
   "language": "python",
   "name": "mlflowtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
