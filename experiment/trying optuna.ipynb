{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d99320b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "174e67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0e5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "file_path = '../data/Loan_Data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4925b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning a bit\n",
    "\n",
    "# 1. drop id col\n",
    "df.drop(columns = ['Loan_ID'], inplace=True)\n",
    "\n",
    "# 2. drop dupe\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 2.1 drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# 3. classify num and cat columns\n",
    "\n",
    "cat_columns = [column for column in df.columns if df[column].dtype == 'object']\n",
    "num_columns = [column for column in df.columns if df[column].dtype != 'object']\n",
    "\n",
    "cat_columns.remove('Loan_Status')\n",
    "\n",
    "\n",
    "\n",
    "# 4. split to training and testing set\n",
    "\n",
    "X = df.drop(columns = 'Loan_Status').copy()\n",
    "y = df['Loan_Status'].copy()\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                    random_state=42,  \n",
    "                                    test_size=0.1,\n",
    "                                    shuffle=True)\n",
    "\n",
    "\n",
    "# 5. encoder\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "encoder.fit(X_train[cat_columns])\n",
    "\n",
    "X_train[cat_columns] = encoder.transform(X_train[cat_columns])    \n",
    "X_test[cat_columns] = encoder.transform(X_test[cat_columns])\n",
    "\n",
    "\n",
    "# 6. scale\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4fdcc4a",
   "metadata": {},
   "source": [
    "# Optuna Part + MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c474405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_logging(exp_param, model, params:dict, metrics:dict):\n",
    "\n",
    "    experiment_name = exp_param['name']\n",
    "    run_name = exp_param['run_name']\n",
    "    artifact_path = exp_param['artifact_path']\n",
    "    model_name = exp_param['model_name']\n",
    "    signature = exp_param['signature']\n",
    "\n",
    "\n",
    "    # set experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "\n",
    "    # initiate the logging\n",
    "    with mlflow.start_run(run_name = run_name, nested=True) as run:\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "\n",
    "        # Log an instance of the trained model for later use\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,  \n",
    "            artifact_path=artifact_path,\n",
    "            registered_model_name= model_name,\n",
    "            signature=signature\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8298798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up mlflow client\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f536614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create experiment\n",
    "\n",
    "experiment_description = (\n",
    "    \"This is the application loan prediction project\"\n",
    "    \"This experiment contains the base experiments made\"\n",
    ")\n",
    "\n",
    "data_clean_made = (\n",
    "    \"remove id col, remove duplicate, [remove missing], categorical encoder, standard scaler\"\n",
    ")\n",
    "\n",
    "model_involved = (\n",
    "    \"Logistic Regression\"\n",
    "    \"AdaBoost\"\n",
    ")\n",
    "\n",
    "other_tag = (\n",
    "    \"Optuna\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"loan_application_project\",\n",
    "    \"team\": \"syamil\",\n",
    "    \"project_quarter\": \"Q1-2024\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "    \"data_cleaning\" : data_clean_made,\n",
    "    \"mode_involved\" : model_involved,\n",
    "    \"other_tag\" : other_tag\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "create_experiment = client.create_experiment(\n",
    "    name=\"Loan_Application_Classification\", tags=experiment_tags\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'first_experiment'\n",
    "run_name = \"first_run\"\n",
    "artifact_path = 'loan_application_model'\n",
    "model_name = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58eb8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_ex, X_train, y_train, X_test, y_test, params:dict):\n",
    "\n",
    "    #logging.info(\"Running up Logistic Regression...\")\n",
    "\n",
    "    # run logistic regression model\n",
    "    model = model_ex.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_valid = model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "    # trying to get the signature \n",
    "    # -> (responsible to save the schema of model input and output)\n",
    "    predictions = model.predict(X_test)\n",
    "    signature = infer_signature(X_test, predictions)\n",
    "    \n",
    "    \n",
    "    return model, score_train, score_valid, signature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2336413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna code\n",
    "\n",
    "def objective(trial, name, model):\n",
    "    \n",
    "    #with mlflow.start_run(nested=True):\n",
    "    \n",
    "    \n",
    "        # Adaboost classification\n",
    "        if name == 'AdaBoost':\n",
    "            params = {\n",
    "                'n_estimators' : trial.suggest_int('n_estimators',100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate',0.0, 1.0),\n",
    "                'algorithm' : trial.suggest_categorical('algorithm',['SAMME','SAMME.R'])\n",
    "            }\n",
    "            \n",
    "        # Logistic Regression\n",
    "        elif name == 'Logistic_Regression':    \n",
    "\n",
    "            penalty_choices = ['l1', 'l2', 'elasticnet']\n",
    "\n",
    "            params = {\n",
    "                #'penalty' : trial.suggest_categorical('penalty', [None, 'l2', 'l1', 'elasticnet']),\n",
    "                'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "                'solver': trial.suggest_categorical('solver', ['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']),\n",
    "                'max_iter': trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "        model = model.set_params(**params)\n",
    "\n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "        score\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "#study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "\n",
    "#study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a44f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'base_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "46d80103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-14 11:42:49,436] A new study created in memory with name: no-name-c6987f2b-87d8-4fbb-8ace-d93b8ff815d9\n",
      "[I 2024-04-14 11:42:49,467] Trial 0 finished with value: 75.43972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 734}. Best is trial 0 with value: 75.43972199946538.\n",
      "[I 2024-04-14 11:42:49,492] Trial 1 finished with value: 79.86367281475542 and parameters: {'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 631}. Best is trial 1 with value: 79.86367281475542.\n",
      "[I 2024-04-14 11:42:49,509] Trial 2 finished with value: 79.86367281475542 and parameters: {'class_weight': None, 'solver': 'liblinear', 'max_iter': 604}. Best is trial 1 with value: 79.86367281475542.\n",
      "[I 2024-04-14 11:42:49,554] Trial 3 finished with value: 75.43972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 240}. Best is trial 1 with value: 79.86367281475542.\n",
      "[I 2024-04-14 11:42:49,579] Trial 4 finished with value: 75.43972199946538 and parameters: {'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 732}. Best is trial 1 with value: 79.86367281475542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'solver': 'liblinear', 'max_iter': 734}\n",
      "{'class_weight': None, 'solver': 'newton-cholesky', 'max_iter': 631}\n",
      "{'class_weight': None, 'solver': 'liblinear', 'max_iter': 604}\n",
      "{'class_weight': 'balanced', 'solver': 'newton-cg', 'max_iter': 240}\n",
      "{'class_weight': 'balanced', 'solver': 'newton-cholesky', 'max_iter': 732}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/14 11:42:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\USER\\AppData\\Local\\Temp\\tmp04ods8fw\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==1.3.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mlflowtest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'Logistic_Regression_best_params'.\n",
      "2024/04/14 11:42:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Logistic_Regression_best_params, version 1\n",
      "Created version '1' of model 'Logistic_Regression_best_params'.\n"
     ]
    }
   ],
   "source": [
    "# trying to combine two classifier\n",
    "\n",
    "names = [\n",
    "    'Logistic_Regression',\n",
    "    #'AdaBoost'\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    #AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "optuna_study = {}\n",
    "\n",
    "def model_training(model, X_train, y_train, X_test, y_test):\n",
    "    model_fitted = model.fit(X_train, y_train)\n",
    "    y_pred = model_fitted.predict(X_test)\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    return model, round(score,3)\n",
    "\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    \n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name) as parent_run:\n",
    "        \n",
    "        # get mlflow id\n",
    "        run_id = parent_run.info.run_id\n",
    "        \n",
    "        #score = model_training(model,X_train, y_train, X_test, y_test)\n",
    "        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
    "        objective_fn = lambda trial: objective(trial, name, model)\n",
    "        study.optimize(objective_fn, n_trials=5)\n",
    "        \n",
    "        for i, trial in enumerate(study.trials):\n",
    "            with mlflow.start_run(run_name=f\"{run_name}_{name}_trial_{i+1}\",nested=True):\n",
    "                mlflow.log_params(trial.params)\n",
    "                mlflow.log_metric('accuracy', trial.value)    \n",
    "            \n",
    "                \n",
    "        \n",
    "        # update the best model run with unseen data\n",
    "        \n",
    "        model, score_train, score_valid, signature = train_model(model, X_train, y_train, X_test, y_test, study.best_params)\n",
    "\n",
    "        # update the run in experiemnt\n",
    "        exp_param = {\n",
    "            'name' : 'Loan_Application_Classification',\n",
    "            'run_name': f'{run_name}_{name}_best_params',\n",
    "            'artifact_path': f'loan_application_model/{run_name}',\n",
    "            'model_name': f'{name}_best_params', \n",
    "            'signature': signature\n",
    "        }\n",
    "        \n",
    "        model_params = study.best_params\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy Training' : score_train,\n",
    "            'Accuracy Test' : score_valid \n",
    "        }\n",
    "        \n",
    "        mlflow_logging(exp_param, model, model_params, metrics)\n",
    "\n",
    "        optuna_study[name] = study\n",
    "\n",
    "        #print(f'{name}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0d461d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/615822914642047264', creation_time=1713065435867, experiment_id='615822914642047264', last_update_time=1713065435867, lifecycle_stage='active', name='Loan_Application_Classification', tags={'data_cleaning': 'remove id col, remove duplicate, [remove missing], '\n",
       "                   'categorical encoder, standard scaler',\n",
       "  'mlflow.note.content': 'This is the application loan prediction project This '\n",
       "                         'experiment contains the base experiments made',\n",
       "  'mode_involved': 'Logistic RegressionAdaBoost',\n",
       "  'other_tag': 'Optuna',\n",
       "  'project_name': 'loan_application_project',\n",
       "  'project_quarter': 'Q1-2024',\n",
       "  'team': 'syamil'}>,\n",
       " <Experiment: artifact_location='file:///C:/Users/USER/Desktop/MLOPS%20NEW/E2E%20Loan%20Application%20Classification/E2E_Loan_Application/experiment/mlruns/0', creation_time=1713012293169, experiment_id='0', last_update_time=1713012293169, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get experiment info\n",
    "\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45242d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflowtest",
   "language": "python",
   "name": "mlflowtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
